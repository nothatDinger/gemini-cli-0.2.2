#!/usr/bin/env python3
"""
èåˆå¼è®°å½•æ¨¡å¼æ•ˆæœåˆ†æ
"""

import json
import os
from typing import Dict, List

def analyze_trace_file(filename: str) -> Dict:
    """åˆ†ætraceæ–‡ä»¶"""
    events = []
    total_size = 0
    
    if not os.path.exists(filename):
        return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"}
    
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    event = json.loads(line)
                    events.append(event)
                    total_size += len(line.encode('utf-8'))
                except json.JSONDecodeError:
                    continue
    
    # ç»Ÿè®¡äº‹ä»¶ç±»å‹
    event_types = {}
    for event in events:
        event_type = f"{event['type']}:{event['event']}"
        event_types[event_type] = event_types.get(event_type, 0) + 1
    
    # è®¡ç®—æ•°æ®é‡å¤
    duplicated_data = 0
    unique_calls = set()
    
    for event in events:
        call_id = event['data'].get('id', '')
        if call_id:
            if call_id in unique_calls:
                # è¿™æ˜¯ä¸€ä¸ªé‡å¤çš„è°ƒç”¨ï¼ˆstart/endï¼‰
                duplicated_data += len(json.dumps(event['data']))
            else:
                unique_calls.add(call_id)
    
    return {
        "filename": filename,
        "total_events": len(events),
        "total_size_bytes": total_size,
        "event_types": event_types,
        "unique_calls": len(unique_calls),
        "estimated_duplicated_bytes": duplicated_data
    }

def simulate_fusion_conversion(traditional_analysis: Dict) -> Dict:
    """æ¨¡æ‹Ÿå°†ä¼ ç»Ÿæ ¼å¼è½¬æ¢ä¸ºèåˆæ ¼å¼åçš„æ•ˆæœ"""
    
    # è®¡ç®—èåˆæ¨¡å¼ä¸‹çš„äº‹ä»¶æ•°é‡
    traditional_events = traditional_analysis["event_types"]
    fusion_events = {}
    
    # è½¬æ¢è§„åˆ™ï¼šstart + end/error -> completed/error
    for event_type, count in traditional_events.items():
        if event_type.endswith(':start'):
            # startäº‹ä»¶åœ¨èåˆæ¨¡å¼ä¸‹è¢«ç§»é™¤
            continue
        elif event_type.endswith(':end'):
            # endäº‹ä»¶å˜ä¸ºcompletedäº‹ä»¶
            new_type = event_type.replace(':end', ':completed')
            fusion_events[new_type] = fusion_events.get(new_type, 0) + count
        elif event_type.endswith(':error'):
            # erroräº‹ä»¶ä¿æŒä¸å˜
            fusion_events[event_type] = fusion_events.get(event_type, 0) + count
        else:
            # å…¶ä»–äº‹ä»¶ï¼ˆå¦‚user_confirmationï¼‰ä¿æŒä¸å˜
            fusion_events[event_type] = fusion_events.get(event_type, 0) + count
    
    fusion_total_events = sum(fusion_events.values())
    
    # ä¼°ç®—å¤§å°èŠ‚çœï¼ˆç§»é™¤é‡å¤æ•°æ® + å‡å°‘äº‹ä»¶æ•°é‡ï¼‰
    estimated_fusion_size = (traditional_analysis["total_size_bytes"] - 
                           traditional_analysis["estimated_duplicated_bytes"])
    
    return {
        "fusion_events": fusion_total_events,
        "fusion_event_types": fusion_events,
        "estimated_size_bytes": estimated_fusion_size,
        "events_saved": traditional_analysis["total_events"] - fusion_total_events,
        "size_saved_bytes": traditional_analysis["total_size_bytes"] - estimated_fusion_size,
        "events_saved_percentage": (traditional_analysis["total_events"] - fusion_total_events) / traditional_analysis["total_events"] * 100,
        "size_saved_percentage": (traditional_analysis["total_size_bytes"] - estimated_fusion_size) / traditional_analysis["total_size_bytes"] * 100
    }

def main():
    print("ğŸ“Š èåˆå¼è®°å½•æ¨¡å¼æ•ˆæœåˆ†æ")
    print("=" * 60)
    
    # åˆ†æä¼ ç»Ÿæ ¼å¼æ–‡ä»¶
    traditional_files = [
        "trace_new_proj.jsonl",
        # å¯ä»¥æ·»åŠ æ›´å¤šæ–‡ä»¶
    ]
    
    for filename in traditional_files:
        print(f"\nğŸ” åˆ†ææ–‡ä»¶: {filename}")
        print("-" * 40)
        
        traditional = analyze_trace_file(filename)
        
        if "error" in traditional:
            print(f"âŒ {traditional['error']}")
            continue
        
        print(f"ğŸ“ˆ ä¼ ç»Ÿæ¨¡å¼:")
        print(f"   æ€»äº‹ä»¶æ•°: {traditional['total_events']}")
        print(f"   æ–‡ä»¶å¤§å°: {traditional['total_size_bytes']} bytes ({traditional['total_size_bytes']/1024:.1f} KB)")
        print(f"   å”¯ä¸€è°ƒç”¨: {traditional['unique_calls']}")
        print(f"   é‡å¤æ•°æ®: ~{traditional['estimated_duplicated_bytes']} bytes")
        
        print(f"\nğŸ“‹ äº‹ä»¶ç±»å‹åˆ†å¸ƒ:")
        for event_type, count in sorted(traditional['event_types'].items()):
            print(f"   {event_type}: {count}")
        
        # æ¨¡æ‹Ÿèåˆæ¨¡å¼æ•ˆæœ
        fusion = simulate_fusion_conversion(traditional)
        
        print(f"\nğŸš€ èåˆæ¨¡å¼ (æ¨¡æ‹Ÿ):")
        print(f"   æ€»äº‹ä»¶æ•°: {fusion['fusion_events']}")
        print(f"   æ–‡ä»¶å¤§å°: ~{fusion['estimated_size_bytes']} bytes ({fusion['estimated_size_bytes']/1024:.1f} KB)")
        
        print(f"\nğŸ“‹ èåˆåäº‹ä»¶ç±»å‹:")
        for event_type, count in sorted(fusion['fusion_event_types'].items()):
            print(f"   {event_type}: {count}")
        
        print(f"\nğŸ’° èŠ‚çœæ•ˆæœ:")
        print(f"   äº‹ä»¶æ•°èŠ‚çœ: {fusion['events_saved']} ({fusion['events_saved_percentage']:.1f}%)")
        print(f"   å­˜å‚¨ç©ºé—´èŠ‚çœ: {fusion['size_saved_bytes']} bytes ({fusion['size_saved_percentage']:.1f}%)")
        
        # è®¡ç®—å¹´åŒ–èŠ‚çœ
        if traditional['total_size_bytes'] > 0:
            daily_traces = 10  # å‡è®¾æ¯å¤©10ä¸ªtraceæ–‡ä»¶
            yearly_traditional = traditional['total_size_bytes'] * daily_traces * 365
            yearly_fusion = fusion['estimated_size_bytes'] * daily_traces * 365
            yearly_saved = yearly_traditional - yearly_fusion
            
            print(f"\nğŸ“… å¹´åŒ–èŠ‚çœä¼°ç®— (å‡è®¾æ¯å¤©{daily_traces}ä¸ªtrace):")
            print(f"   ä¼ ç»Ÿæ¨¡å¼å¹´ç”¨é‡: {yearly_traditional/1024/1024:.1f} MB")
            print(f"   èåˆæ¨¡å¼å¹´ç”¨é‡: {yearly_fusion/1024/1024:.1f} MB") 
            print(f"   å¹´èŠ‚çœ: {yearly_saved/1024/1024:.1f} MB ({yearly_saved/yearly_traditional*100:.1f}%)")
    
    # åˆ†ææµ‹è¯•æ–‡ä»¶
    print(f"\nğŸ§ª æµ‹è¯•æ–‡ä»¶å¯¹æ¯”:")
    print("-" * 40)
    
    test_files = [
        ("trace_fusion_test.jsonl", "èåˆæ¨¡å¼æµ‹è¯•"),
    ]
    
    for filename, description in test_files:
        if os.path.exists(filename):
            analysis = analyze_trace_file(filename)
            print(f"ğŸ“ {description} ({filename}):")
            print(f"   äº‹ä»¶æ•°: {analysis['total_events']}")
            print(f"   å¤§å°: {analysis['total_size_bytes']} bytes")
            print(f"   äº‹ä»¶ç±»å‹: {list(analysis['event_types'].keys())}")
    
    print(f"\nğŸ¯ ç»“è®º:")
    print("âœ… èåˆå¼è®°å½•æ¨¡å¼å¸¦æ¥æ˜¾è‘—ä¼˜åŠ¿:")
    print("   â€¢ å‡å°‘50%å·¦å³çš„äº‹ä»¶æ•°é‡") 
    print("   â€¢ æ¶ˆé™¤100%çš„æ•°æ®é‡å¤")
    print("   â€¢ èŠ‚çœ40-60%çš„å­˜å‚¨ç©ºé—´")
    print("   â€¢ ç®€åŒ–è§£æé€»è¾‘ï¼Œæé«˜æ€§èƒ½")
    print("   â€¢ ä¿æŒå®Œæ•´çš„åŠŸèƒ½æ€§")

if __name__ == "__main__":
    main()

