#!/usr/bin/env python3
"""
è§£ætraceæ–‡ä»¶ä¸­çš„dataå†…å®¹ï¼Œè½¬æ¢ä¸ºæ ‡å‡†JSONæ ¼å¼
"""

import json
import argparse
from typing import Dict, Any, List
from pathlib import Path

class TraceDataParser:
    def __init__(self, trace_file: str):
        self.trace_file = trace_file
        self.parsed_data = []
    
    def parse_trace_file(self) -> List[Dict[str, Any]]:
        """è§£ætraceæ–‡ä»¶ï¼Œæå–dataå†…å®¹"""
        print(f"ğŸ“– æ­£åœ¨è§£ææ–‡ä»¶: {self.trace_file}")
        
        try:
            with open(self.trace_file, 'r', encoding='utf-8') as f:
                line_count = 0
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                        
                    try:
                        # è§£æJSONLè¡Œ
                        event = json.loads(line)
                        line_count += 1
                        
                        # æå–dataå­—æ®µ
                        if 'data' in event:
                            data_entry = {
                                'line_number': line_count,
                                'timestamp': event.get('timestamp', ''),
                                'type': event.get('type', ''),
                                'event': event.get('event', ''),
                                'data': event['data']
                            }
                            
                            # å°è¯•è§£ædataä¸­çš„JSONå­—ç¬¦ä¸²å­—æ®µ
                            data_entry['data'] = self._parse_nested_json(event['data'])
                            
                            self.parsed_data.append(data_entry)
                        
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  ç¬¬{line_count}è¡ŒJSONè§£æé”™è¯¯: {e}")
                        continue
                        
            print(f"âœ… æˆåŠŸè§£æ {len(self.parsed_data)} æ¡è®°å½•")
            return self.parsed_data
            
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.trace_file}")
            return []
        except Exception as e:
            print(f"âŒ è§£ææ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return []
    
    def _parse_nested_json(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """é€’å½’è§£ædataä¸­çš„JSONå­—ç¬¦ä¸²å­—æ®µ"""
        parsed_data = {}
        
        for key, value in data.items():
            if isinstance(value, str) and self._is_json_string(value):
                try:
                    # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                    parsed_value = json.loads(value)
                    parsed_data[key] = {
                        'raw': value,
                        'parsed': parsed_value,
                        'type': 'json_string'
                    }
                except json.JSONDecodeError:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œä¿æŒåŸå€¼
                    parsed_data[key] = value
            else:
                parsed_data[key] = value
                
        return parsed_data
    
    def _is_json_string(self, text: str) -> bool:
        """åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦å¯èƒ½æ˜¯JSON"""
        text = text.strip()
        return (text.startswith('{') and text.endswith('}')) or \
               (text.startswith('[') and text.endswith(']'))
    
    def save_to_json(self, output_file: str, indent: int = 2) -> None:
        """ä¿å­˜è§£æç»“æœä¸ºJSONæ–‡ä»¶"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.parsed_data, f, indent=indent, ensure_ascii=False)
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def save_data_only(self, output_file: str, indent: int = 2) -> None:
        """åªä¿å­˜dataå­—æ®µçš„å†…å®¹"""
        try:
            data_only = [entry['data'] for entry in self.parsed_data]
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data_only, f, indent=indent, ensure_ascii=False)
            print(f"ğŸ’¾ Dataå†…å®¹å·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def extract_specific_fields(self, output_file: str, fields: List[str]) -> None:
        """æå–ç‰¹å®šå­—æ®µå¹¶ä¿å­˜"""
        try:
            extracted_data = []
            for entry in self.parsed_data:
                extracted_entry = {}
                for field in fields:
                    if field in entry:
                        extracted_entry[field] = entry[field]
                    elif field in entry.get('data', {}):
                        extracted_entry[field] = entry['data'][field]
                
                if extracted_entry:  # åªæ·»åŠ éç©ºæ¡ç›®
                    extracted_data.append(extracted_entry)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(extracted_data, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ æå–çš„å­—æ®µå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"âŒ æå–å­—æ®µæ—¶å‡ºé”™: {e}")
    
    def print_summary(self) -> None:
        """æ‰“å°è§£ææ‘˜è¦"""
        if not self.parsed_data:
            print("ğŸ“Š æ²¡æœ‰è§£æåˆ°ä»»ä½•æ•°æ®")
            return
        
        print(f"\nğŸ“Š è§£ææ‘˜è¦:")
        print(f"   æ€»è®°å½•æ•°: {len(self.parsed_data)}")
        
        # ç»Ÿè®¡äº‹ä»¶ç±»å‹
        event_types = {}
        for entry in self.parsed_data:
            event_type = f"{entry['type']}.{entry['event']}"
            event_types[event_type] = event_types.get(event_type, 0) + 1
        
        print(f"   äº‹ä»¶ç±»å‹åˆ†å¸ƒ:")
        for event_type, count in sorted(event_types.items()):
            print(f"     {event_type}: {count}")
        
        # æ˜¾ç¤ºæ•°æ®å­—æ®µ
        print(f"\n   å¸¸è§dataå­—æ®µ:")
        all_keys = set()
        for entry in self.parsed_data:
            all_keys.update(entry['data'].keys())
        
        for key in sorted(all_keys):
            count = sum(1 for entry in self.parsed_data if key in entry['data'])
            print(f"     {key}: å‡ºç°åœ¨ {count} æ¡è®°å½•ä¸­")

def main():
    parser = argparse.ArgumentParser(description='è§£ætraceæ–‡ä»¶ä¸­çš„dataå†…å®¹')
    parser.add_argument('trace_file', nargs='?', default='test_trace_1.jsonl',
                       help='traceæ–‡ä»¶è·¯å¾„ (é»˜è®¤: test_trace_1.jsonl)')
    parser.add_argument('-o', '--output', default='parsed_trace_data.json',
                       help='è¾“å‡ºJSONæ–‡ä»¶å (é»˜è®¤: parsed_trace_data.json)')
    parser.add_argument('--data-only', action='store_true',
                       help='åªè¾“å‡ºdataå­—æ®µå†…å®¹')
    parser.add_argument('--fields', nargs='+',
                       help='æå–ç‰¹å®šå­—æ®µ (ä¾‹å¦‚: --fields id model status)')
    parser.add_argument('--indent', type=int, default=2,
                       help='JSONç¼©è¿›ç©ºæ ¼æ•° (é»˜è®¤: 2)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(args.trace_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.trace_file}")
        return
    
    # åˆ›å»ºè§£æå™¨
    parser = TraceDataParser(args.trace_file)
    
    # è§£ææ–‡ä»¶
    data = parser.parse_trace_file()
    if not data:
        print("âŒ æ²¡æœ‰è§£æåˆ°ä»»ä½•æ•°æ®")
        return
    
    # æ‰“å°æ‘˜è¦
    parser.print_summary()
    
    # ä¿å­˜ç»“æœ
    if args.fields:
        parser.extract_specific_fields(args.output, args.fields)
    elif args.data_only:
        parser.save_data_only(args.output, args.indent)
    else:
        parser.save_to_json(args.output, args.indent)
    
    print(f"\nğŸ‰ è§£æå®Œæˆï¼")

if __name__ == "__main__":
    main()
